# Streaming Infrastructure

StreamingovÃ¡ infrastruktura pro core-platform vyuÅ¾Ã­vajÃ­cÃ­ Kafka, PostgreSQL fronty a Outbox pattern.

## ğŸ—ï¸ Architektura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Client    â”‚â”€â”€â”€â”€â”€>â”‚ REST API     â”‚â”€â”€â”€â”€â”€>â”‚ CommandQueueâ”‚â”€â”€â”€â”€â”€>â”‚  Worker  â”‚
â”‚  (REST/UI)  â”‚      â”‚ Controller   â”‚      â”‚  (Postgres) â”‚      â”‚  Service â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                                       â”‚
                                                                       â–¼
                                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                            â”‚  WorkState  â”‚<â”€â”€â”€â”€â”€â”‚ Process  â”‚
                                            â”‚  (Locking)  â”‚      â”‚ Command  â”‚
                                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                                       â”‚
                                                                       â–¼
                                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                            â”‚   Outbox    â”‚<â”€â”€â”€â”€â”€â”‚  Write   â”‚
                                            â”‚   Final     â”‚      â”‚  Event   â”‚
                                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                  â”‚
                                                  â–¼
                                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                            â”‚  Dispatcher  â”‚â”€â”€â”€â”€>â”‚  Kafka   â”‚
                                            â”‚   Service    â”‚     â”‚  Topics  â”‚
                                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“Š Komponenty

### 1. **CommandQueue** - Fronta pÅ™Ã­kazÅ¯
- AsynchronnÃ­ fronty pro CREATE, UPDATE, DELETE, BULK operace
- Priority: `critical` â†’ `high` â†’ `normal` â†’ `bulk`
- Status flow: `pending` â†’ `processing` â†’ `completed` / `failed` / `dlq`
- Retry logic s exponenciÃ¡lnÃ­m backoffem

### 2. **WorkState** - StavovÃ¡ synchronizace
- PesimistickÃ© zÃ¡mky na Ãºrovni entity (FOR UPDATE SKIP LOCKED)
- Single-writer semantika - jen jeden worker mÅ¯Å¾e aktualizovat entitu najednou
- TTL-based expiry (5 min) pro automatickÃ© uvolnÄ›nÃ­ zamrzlÃ½ch lockÅ¯
- Stavy: `idle` â†” `updating`

### 3. **OutboxFinal** - TransakÄnÃ­ outbox
- Garantuje at-least-once delivery do Kafky
- IdempotentnÃ­ publisher (acks=all, transakcional ID)
- Partition key: `{entity}#{entityId}` pro ordering per entity

### 4. **Kafka Topics**
- **Commands**: `{entity}-commands` (24h retention, compacted)
- **Events**: `{entity}-events` (7d retention, compacted)
- **Inflight**: `{entity}-inflight` (30min retention) - pre-event notifikace

### 5. **Metrics & Monitoring**
- **Prometheus**: 15+ metrik (queue depth, latency, errors, DLQ)
- **Grafana**: 3 dashboardy (Overview, Entities, Operations) - dostupnÃ© na `/monitoring/`
  - **streaming-overview**: CelkovÃ½ pÅ™ehled - queue depth, outbox, success rate, latency, DLQ
  - **streaming-entities**: Per-entity metriky - throughput, latency a chyby pro user/group/role/permission
  - **streaming-ops**: OperaÄnÃ­ monitoring - work state, locky, DLQ breakdown, priority queues, error logs
- **Alerts**: Queue threshold, DLQ, P95 latency SLO (30s)
- **Real-time Dashboard**: Admin UI na `/admin/streaming` s live metrikami

## ğŸš€ Quickstart

### 1. Povolit streaming v metamodelu

**GlobÃ¡lnÃ­ config** (`backend/src/main/resources/metamodel/global-config.yaml`):
```yaml
streaming:
  enabled: true
  defaultPartitions: 3
  defaultReplicationFactor: 1
  defaultRetentionHours: 168
```

**Entity config** (`backend/src/main/resources/metamodel/user.yaml`):
```yaml
entity: user
table: users
streaming:
  enabled: true
  partitions: 6
  eventPayloadMode: diff  # full | diff | minimal
  strictReads: true       # return 423 when entity updating
  workerBatchSize: 100
  maxRetries: 3
```

### 2. Spustit Kafka stack

```bash
# Start Kafka + Prometheus + Grafana
docker compose --profile streaming up -d

# Kontrola topiccÅ¯
docker exec kafka kafka-topics.sh --bootstrap-server localhost:9092 --list
```

### 3. Povolit feature flag

**.env**:
```bash
STREAMING_ENABLED=true
```

### 4. NavÅ¡tÃ­vit Admin UI

- **Streaming Dashboard**: http://localhost/core-admin/streaming
- **Kafka UI**: http://localhost:8090
- **Grafana**: http://localhost:3001

## ğŸ“ˆ PouÅ¾itÃ­

### REST API - ZÃ¡pis s priority

```bash
# NormÃ¡lnÃ­ operace
POST /api/users
{
  "email": "test@example.com",
  "firstName": "John",
  "priority": "normal"
}

# KritickÃ¡ operace (pÅ™ednostnÃ­)
POST /api/users
{
  "email": "vip@example.com",
  "priority": "critical"
}

# Bulk import (nÃ­zkÃ¡ priorita)
POST /api/users/bulk
{
  "users": [...],
  "priority": "bulk"
}
```

### Strict Reads - 423 Locked

KdyÅ¾ je `strictReads: true`, GET pÅ™i update vrÃ¡tÃ­ 423:

```bash
GET /api/users/123
HTTP/1.1 423 Locked
{
  "error": "Entity is currently being updated",
  "retryAfter": 5
}
```

### DLQ Management API

```bash
# Seznam DLQ zprÃ¡v
GET /api/admin/streaming/dlq?entity=user&errorType=ValidationException

# Retry jednÃ© zprÃ¡vy
POST /api/admin/streaming/dlq/{id}/retry

# Retry vÅ¡ech DLQ pro entitu
POST /api/admin/streaming/dlq/retry-all?entity=user

# Smazat DLQ zprÃ¡vu
DELETE /api/admin/streaming/dlq/{id}
```

## ğŸ” Monitoring

### Grafana Dashboards

1. **Streaming Overview**
   - CelkovÃ¡ hloubka fronty
   - Unsent outbox zprÃ¡vy
   - Worker success rate
   - DLQ count

2. **Streaming Entities**
   - Per-entity metriky
   - Success rate per entity
   - P95 latency histogram
   - Error breakdown by type

3. **Streaming Operations**
   - Work state transitions
   - Lock expiry rate
   - DLQ by entity table
   - Queue depth by priority

### Prometheus Alerts

- **StreamingQueueDepthHigh**: queue > 1000 (5min)
- **StreamingQueueDepthCritical**: queue > 5000 (2min)
- **StreamingOutboxUnsentGrowing**: roste 10min
- **StreamingLatencyP95High**: P95 > 30s (5min)
- **StreamingDLQMessagesDetected**: novÃ© DLQ zprÃ¡vy
- **StreamingLocksExpiring**: >10 expired lockÅ¯ za 5min

## ğŸ§ª TestovÃ¡nÃ­

### Unit testy

```bash
cd backend
./mvnw test -Dtest=WorkerServiceTest
./mvnw test -Dtest=DispatcherServiceTest
```

### Integration test - AD Sync

```bash
# Simulace AD sync 5000 uÅ¾ivatelÅ¯
POST /api/admin/test/ad-sync
{
  "userCount": 5000,
  "priority": "high"
}

# Kontrola metrik
curl localhost:9090/api/v1/query?query=core_stream_worker_success_total
```

### Load test

```bash
# Apache Bench - 1000 requests, 50 concurrent
ab -n 1000 -c 50 -p user.json -T application/json \
   http://localhost/api/users

# Sledovat Grafana: Streaming Overview
```

### Chaos test

```bash
# ZabÃ­t worker a sledovat queue backlog
docker compose kill backend
sleep 30
docker compose up -d backend

# Kontrola DLQ a recovery
```

## ğŸ› ï¸ Troubleshooting

### Queue backlog

```sql
-- Zjistit hloubku fronty
SELECT status, priority, COUNT(*) 
FROM command_queue 
GROUP BY status, priority;

-- NajÃ­t nejstarÅ¡Ã­ pending
SELECT * FROM command_queue 
WHERE status = 'pending' 
ORDER BY created_at 
LIMIT 10;
```

### ZamrzlÃ© locky

```sql
-- NajÃ­t starÃ© locky
SELECT * FROM work_state 
WHERE state = 'updating' 
  AND locked_at < NOW() - INTERVAL '10 minutes';

-- RuÄnÄ› uvolnit
DELETE FROM work_state 
WHERE state = 'updating' 
  AND locked_at < NOW() - INTERVAL '15 minutes';
```

### DLQ replay

```bash
# Retry vÅ¡ech DLQ pro ValidationException
POST /api/admin/streaming/dlq/retry-all?errorType=ValidationException

# Retry pouze user entity
POST /api/admin/streaming/dlq/retry-all?entity=user
```

### Kafka lag

```bash
# Check consumer lag
docker exec kafka kafka-consumer-groups.sh \
  --bootstrap-server localhost:9092 \
  --describe --group core-platform-events
```

## ğŸ“ PÅ™idÃ¡nÃ­ novÃ© entity do streamingu

1. **Metamodel** - pÅ™idat streaming config:
```yaml
entity: order
streaming:
  enabled: true
  partitions: 3
  eventPayloadMode: full
```

2. **TopicEnsurer** - automaticky vytvoÅ™Ã­ topics pÅ™i startu

3. **EventConsumer** - pÅ™idat listener:
```java
@KafkaListener(topics = "order-events", groupId = "core-platform-events")
public void handleOrderEvent(String message) {
    // Process event
}
```

4. **Controller** - pouÅ¾Ã­t CommandQueue pro zÃ¡pisy:
```java
@PostMapping("/orders")
public ResponseEntity<Order> create(@RequestBody OrderRequest req) {
    Order order = orderService.create(req);
    commandQueueRepository.save(CommandQueue.builder()
        .entity("order")
        .entityId(order.getId())
        .operation("CREATE")
        .priority(req.getPriority())
        .payload(mapper.writeValueAsString(order))
        .build());
    return ok(order);
}
```

## ğŸ§ª Testing & CI

### Pre-Deploy Testing Stack

KompletnÃ­ testovacÃ­ infrastruktura zajiÅ¡Å¥uje kvalitu pÅ™ed nasazenÃ­m do produkce.

#### Backend Tests

**1. Static Analysis** (Maven profiles)
```bash
# Maven Enforcer - duplicate classes, dependency convergence
cd backend && ./mvnw validate -P enforce-rules

# OWASP Dependency-Check - CVE scan (fail on CVSS >= 7)
./mvnw verify -P security -DskipTests

# JaCoCo Coverage - 70% minimum line coverage
./mvnw test jacoco:check -P unit-tests
```

**2. Unit Tests** (Surefire)
```bash
cd backend && ./mvnw test -P unit-tests
```

**3. Integration Tests** (Failsafe + Testcontainers)
```bash
cd backend && ./mvnw verify -P integration-tests

# Test suites:
# - PostgresStreamingIT: SKIP LOCKED batching, deduplication, TTL
# - KafkaStreamingIT: topic config, entity keying, partition consistency
# - PriorityAndPoliciesIT: priority lanes, strict reads, PII redaction
# - OpenApiContractIT: API contract validation, exports openapi.json
```

#### Frontend Tests

**1. Unit Tests** (Vitest + React Testing Library)
```bash
cd frontend

# Verify React version (no duplicates)
npm run verify:react

# Run unit tests with coverage
npm run test:unit
```

**2. E2E Tests** (Playwright)
```bash
# Start compose stack
./scripts/e2e-setup.sh

# Run E2E tests
cd frontend && npm run test:e2e

# Teardown
./scripts/e2e-teardown.sh
```

#### Infrastructure Tests

**Compose Stack Smoke Tests**
```bash
# Start streaming profile
docker compose --profile streaming up -d

# Run smoke tests
./scripts/infra-smoke-test.sh

# Tests:
# - /actuator/health, /actuator/prometheus
# - Kafka topics via kafka-topics.sh
# - Topic policies: cleanup.policy=compact, retention.ms
# - Grafana provisioning: /api/search?query=Streaming
# - Prometheus targets health
# - Mini flow: POST command â†’ status==APPLIED
```

**Alert Validation**
```bash
# Validate Prometheus alert rules
./scripts/validate-alerts.sh

# Checks:
# - YAML syntax (yamllint)
# - PromQL syntax via Prometheus API
# - Expected alert names (9 rules)
# - Dry-run evaluation against metrics
# - Annotations (severity, summary, description)
```

### CI Pipeline (GitHub Actions)

Workflow: `.github/workflows/streaming-tests.yml`

**Jobs:**
1. **backend-static**: Maven Enforcer + OWASP
2. **backend-unit**: Unit tests + JaCoCo 70%
3. **backend-it**: Testcontainers IT + OpenAPI export
4. **frontend-unit**: Vitest + React dedupe check
5. **compose-smoke**: Docker Compose + infra-smoke-test.sh
6. **frontend-e2e**: Playwright with Chromium
7. **image-scan**: Trivy CRITICAL/HIGH vulnerabilities

**Artifacts:**
- OWASP reports (HTML/JSON)
- JaCoCo coverage reports
- OpenAPI spec (`openapi.json`)
- Playwright HTML report
- Docker logs (on failure)

**Branch Protection:**
- All jobs must pass
- 70% code coverage minimum
- No CRITICAL/HIGH CVEs

### Test Reports

**After CI run:**
- Coverage: `backend/target/site/jacoco/index.html`
- OWASP: `backend/target/dependency-check-report.html`
- Playwright: `frontend/playwright-report/index.html`
- OpenAPI spec: `backend/target/openapi/openapi.json`

## ğŸ” Security

- Admin UI: Role `PlatformAdmin` nebo `Ops`
- DLQ API: `@PreAuthorize("hasAnyRole('PlatformAdmin', 'Ops')")`
- Kafka: SASL/PLAIN (produkce), PLAINTEXT (dev)
- Grafana: OAuth2 s Keycloak (produkce)

## ğŸ¤– AI Hooks (META_ONLY)

**Since:** 2025-10-14

StreamingovÃ¡ infrastruktura je integrovÃ¡na s AI hooks pro in-app agenty:

### AI Context Export

```bash
# Get workflow context for streaming entities
curl http://localhost:8080/api/ai/mcp/wf_context/get_workflow \
  -X POST -H "Content-Type: application/json" \
  -d '{"entity": "WorkflowDraft"}'
```

Returns:
- Workflow states (draft, pending, approved, etc.)
- Actions with `howto` steps
- Streaming priority annotations (`CRITICAL`, `HIGH`, `NORMAL`, `BULK`)

### Streaming-Specific Metadata

Entity schemas contain streaming config:

```yaml
# workflow-draft.yaml
streaming:
  enabled: true
  priority: normal
  strictReads: true
  
transitions:
  - code: submit
    streamingPriority: HIGH  # Affects queue priority
    howto:
      - "Validate draft completeness"
      - "Click Submit button"
      - "Command queued with HIGH priority"
```

### Strict Reads Integration

AI context respects `strictReads`:

```bash
# Strict mode: returns 423 if entity is UPDATING
curl "http://localhost:8080/api/ai/context?routeId=workflow-draft.edit&strict=true"

# Non-strict: returns 200 + state.updating=true
curl "http://localhost:8080/api/ai/context?routeId=workflow-draft.edit&strict=false"
```

### Telemetry

AI metrics for streaming actions:

```promql
# AI requests for streaming entities
ai_requests_total{route=~"workflow-.*"}

# Help requests for streaming workflows
ai_help_requests_total{route=~"workflow-.*"}
```

**See:** `docs/AI_GUIDE.md` for complete AI documentation

## ğŸ“š Reference

- **Outbox Pattern**: https://microservices.io/patterns/data/transactional-outbox.html
- **Kafka Idempotence**: https://kafka.apache.org/documentation/#producerconfigs_enable.idempotence
- **Prometheus Metrics**: http://localhost:8080/actuator/prometheus
- **Kafka UI**: http://localhost:8090
- **Grafana**: http://localhost:3001
- **AI Guide**: `docs/AI_GUIDE.md`

## ğŸ› Known Issues

- Backend KeycloakAdminService mÃ¡ chyby v UserUpdateRequest - nenÃ­ souÄÃ¡stÃ­ streaming featury
- Frontend StreamingDashboardPage zatÃ­m nemÃ¡ real-time metrics endpoint - placeholder

## ğŸš§ Roadmap

- [ ] Kafka Schema Registry pro Avro/Protobuf
- [ ] Dead Letter Queue UI s filtering a bulk retry
- [ ] Distributed tracing (Jaeger) pro command flow
- [ ] Multi-DC replication (Kafka MirrorMaker)
- [ ] Event versioning a schema evolution
