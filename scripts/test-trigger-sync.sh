#!/bin/bash

# ðŸ”„ Enhanced Test Script pro PostgreSQL Trigger Synchronization System V4
# OvÄ›Å™uje funkÄnost optimalizovanÃ©ho systÃ©mu vÄetnÄ› novÃ½ch features

set -e

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
DOMAIN=${DOMAIN:-core-platform.local}
ADMIN_URL="https://admin.${DOMAIN}"

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

print_success() { echo -e "${GREEN}âœ… $1${NC}"; }
print_info() { echo -e "${BLUE}â„¹ï¸  $1${NC}"; }
print_warning() { echo -e "${YELLOW}âš ï¸  $1${NC}"; }
print_error() { echo -e "${RED}âŒ $1${NC}"; }

echo -e "${BLUE}"
echo "ðŸ”„ =============================================="
echo "   PostgreSQL Trigger Sync V4 - Test Suite"
echo "   Domain: ${DOMAIN}"
echo "   Optimizations: NOOP detection, Batch delete,"
echo "                 Reconnect logic, Buffer overflow"
echo "==============================================="
echo -e "${NC}"

# 1. Enhanced health check
print_info "1. Testing enhanced system health..."
if curl -sf "${ADMIN_URL}/api/admin/change-events/health" > /tmp/health.json; then
    STATUS=$(cat /tmp/health.json | jq -r '.status // "UNKNOWN"')
    LISTENING=$(cat /tmp/health.json | jq -r '.processor.listening // false')
    CONNECTION_VALID=$(cat /tmp/health.json | jq -r '.processor.connectionValid // false')
    UNPROCESSED=$(cat /tmp/health.json | jq -r '.database.unprocessedEvents // 0')
    RECONNECT_ATTEMPTS=$(cat /tmp/health.json | jq -r '.processor.reconnectAttempts // 0')
    
    print_info "Status: ${STATUS}"
    print_info "Listening: ${LISTENING}"
    print_info "Connection Valid: ${CONNECTION_VALID}"
    print_info "Unprocessed events: ${UNPROCESSED}"
    print_info "Reconnect attempts: ${RECONNECT_ATTEMPTS}"
    
    if [ "$STATUS" = "UP" ] && [ "$LISTENING" = "true" ] && [ "$CONNECTION_VALID" = "true" ]; then
        print_success "Enhanced health check passed"
    else
        print_error "Health check failed"
        cat /tmp/health.json | jq .
        exit 1
    fi
else
    print_error "Failed to connect to health endpoint"
    exit 1
fi

# 2. Test V4 optimizations configuration
print_info "2. Testing V4 optimizations configuration..."
if curl -sf "${ADMIN_URL}/api/admin/change-events/config" > /tmp/config.json; then
    SYSTEM_TYPE=$(cat /tmp/config.json | jq -r '.systemType')
    MAX_BUFFER_SIZE=$(cat /tmp/config.json | jq -r '.maxBufferSize')
    DELETE_BATCH_SIZE=$(cat /tmp/config.json | jq -r '.deleteBatchSize')
    OPTIMIZATIONS=$(cat /tmp/config.json | jq -r '.optimizations | length')
    
    print_info "System: ${SYSTEM_TYPE}"
    print_info "Max buffer size: ${MAX_BUFFER_SIZE}"
    print_info "Delete batch size: ${DELETE_BATCH_SIZE}"
    print_info "Active optimizations: ${OPTIMIZATIONS}"
    
    if [[ "$SYSTEM_TYPE" == *"Optimized V4"* ]]; then
        print_success "V4 optimizations configuration check passed"
    else
        print_error "Wrong system type: $SYSTEM_TYPE"
        exit 1
    fi
else
    print_error "Failed to get configuration"
    exit 1
fi

# 3. Test enhanced database structure
print_info "3. Testing V4 database structure..."
DB_RESULT=$(docker exec core-db psql -U core -d core -c "
SELECT 
    EXISTS(SELECT 1 FROM pg_proc WHERE proname = 'fn_notify_user_entity_change_optimized') as optimized_trigger_exists,
    EXISTS(SELECT 1 FROM pg_proc WHERE proname = 'batch_delete_processed_events') as batch_delete_exists,
    EXISTS(SELECT 1 FROM pg_proc WHERE proname = 'bulk_mark_events_processed') as bulk_mark_exists,
    EXISTS(SELECT 1 FROM information_schema.views WHERE table_name = 'v_user_change_events_stats') as stats_view_exists;
" -t -A -F'|')

if echo "$DB_RESULT" | grep -q "t|t|t|t"; then
    print_success "V4 database structure check passed"
else
    print_error "V4 database structure incomplete"
    echo "Result: $DB_RESULT"
    exit 1
fi

# 4. Test database statistics views
print_info "4. Testing database statistics views..."
if curl -sf "${ADMIN_URL}/api/admin/change-events/db-stats" > /tmp/db_stats.json; then
    OVERALL_STATS=$(cat /tmp/db_stats.json | jq -r '.overall != null')
    TOP_REALMS=$(cat /tmp/db_stats.json | jq -r '.topRealms | length')
    
    if [ "$OVERALL_STATS" = "true" ]; then
        print_success "Database statistics views working"
        print_info "Top realms tracked: ${TOP_REALMS}"
    else
        print_warning "Database statistics views not returning data (may be empty)"
    fi
else
    print_error "Failed to get database statistics"
    exit 1
fi

# 5. Test NOOP update detection
print_info "5. Testing NOOP update detection..."
TEST_USER_ID=$(uuidgen)

# VloÅ¾Ã­me test user do Keycloak DB
docker exec core-db psql -U core -d core -c "
INSERT INTO public.user_entity (id, username, email, first_name, last_name, enabled, realm_id, created_timestamp)
VALUES (
    '${TEST_USER_ID}',
    'noop-test-user',
    'noop@test.com',
    'NOOP',
    'User',
    true,
    (SELECT id FROM public.realm WHERE name = 'core-platform' LIMIT 1),
    extract(epoch from now()) * 1000
);
" 2>/dev/null || print_warning "User insert failed (may not have Keycloak DB structure in test)"

# PoÄkÃ¡me na initial sync
sleep 2

# PoÄet eventÅ¯ pÅ™ed NOOP update
EVENTS_BEFORE=$(docker exec core-db psql -U core -d core -c "SELECT COUNT(*) FROM user_change_events WHERE processed = false;" -t -A)

# Provedeme NOOP update (stejnÃ© hodnoty)
docker exec core-db psql -U core -d core -c "
UPDATE public.user_entity 
SET first_name = 'NOOP', email = 'noop@test.com' 
WHERE id = '${TEST_USER_ID}';
" 2>/dev/null || print_info "NOOP update skipped (test DB may not have user_entity)"

sleep 2

# PoÄet eventÅ¯ po NOOP update
EVENTS_AFTER=$(docker exec core-db psql -U core -d core -c "SELECT COUNT(*) FROM user_change_events WHERE processed = false;" -t -A)

if [ "$EVENTS_BEFORE" -eq "$EVENTS_AFTER" ]; then
    print_success "NOOP update detection working - no events generated"
else
    print_warning "NOOP update detection may not be working (events: $EVENTS_BEFORE -> $EVENTS_AFTER)"
fi

# 6. Test batch delete functionality
print_info "6. Testing batch delete functionality..."

# VytvoÅ™Ã­me nÄ›kolik processed eventÅ¯ pro test
docker exec core-db psql -U core -d core -c "
INSERT INTO user_change_events (user_id, operation, realm_id, payload, processed, processed_at)
SELECT 
    gen_random_uuid(),
    'UPDATE',
    'test-realm',
    '{\"username\": \"batch-test\"}',
    true,
    NOW() - INTERVAL '1 day'
FROM generate_series(1, 5);
"

# SpoÄÃ­tÃ¡me processed eventy pÅ™ed cleanup
PROCESSED_BEFORE=$(docker exec core-db psql -U core -d core -c "SELECT COUNT(*) FROM user_change_events WHERE processed = true;" -t -A)

# Test batch cleanup
if curl -sf -X POST "${ADMIN_URL}/api/admin/change-events/cleanup?daysOld=0&batchSize=10" > /tmp/cleanup.json; then
    CLEANUP_STATUS=$(cat /tmp/cleanup.json | jq -r '.status')
    TOTAL_DELETED=$(cat /tmp/cleanup.json | jq -r '.totalDeleted // 0')
    
    if [ "$CLEANUP_STATUS" = "success" ]; then
        print_success "Batch delete test passed - deleted $TOTAL_DELETED events"
    else
        print_error "Batch delete failed: $(cat /tmp/cleanup.json | jq -r '.message')"
        exit 1
    fi
else
    print_error "Failed to trigger batch cleanup"
    exit 1
fi

# 7. Test reconnect functionality
print_info "7. Testing reconnect functionality..."
if curl -sf -X POST "${ADMIN_URL}/api/admin/change-events/reconnect" > /tmp/reconnect.json; then
    RECONNECT_STATUS=$(cat /tmp/reconnect.json | jq -r '.status')
    
    if [ "$RECONNECT_STATUS" = "success" ]; then
        print_success "Reconnect test initiated successfully"
        
        # PoÄkÃ¡me na reconnect
        sleep 5
        
        # OvÄ›Å™Ã­me Å¾e listening je opÄ›t aktivnÃ­
        if curl -sf "${ADMIN_URL}/api/admin/change-events/health" > /tmp/reconnect_health.json; then
            LISTENING_AFTER=$(cat /tmp/reconnect_health.json | jq -r '.processor.listening // false')
            
            if [ "$LISTENING_AFTER" = "true" ]; then
                print_success "Reconnect functionality working"
            else
                print_warning "Reconnect may still be in progress"
            fi
        fi
    else
        print_error "Reconnect test failed"
        exit 1
    fi
else
    print_error "Failed to trigger reconnect"
    exit 1
fi

# 8. Test buffer overflow protection
print_info "8. Testing buffer overflow protection..."

# Simulujeme buffer overflow s vÃ­ce notifikacemi neÅ¾ buffer limit
for i in {1..150}; do
    TEST_USER_ID=$(uuidgen)
    docker exec core-db psql -U core -d core -c "NOTIFY user_entity_changed, '${TEST_USER_ID}';" &
done

# PoÄkÃ¡me na zpracovÃ¡nÃ­
sleep 5

# Zkontrolujeme Å¾e buffer se vyprÃ¡zdnil (force flush)
if curl -sf "${ADMIN_URL}/api/admin/change-events/health" > /tmp/buffer_health.json; then
    PENDING_COUNT=$(cat /tmp/buffer_health.json | jq -r '.processor.pendingUserIds // 0')
    
    if [ "$PENDING_COUNT" -lt 100]; then
        print_success "Buffer overflow protection working - pending: $PENDING_COUNT"
    else
        print_warning "Buffer overflow may not have triggered force flush - pending: $PENDING_COUNT"
    fi
fi

# 9. Test performance with detailed stats
print_info "9. Testing performance with detailed statistics..."
if curl -sf "${ADMIN_URL}/api/admin/change-events/stats" > /tmp/detailed_stats.json; then
    AVG_PROCESSING_TIME=$(cat /tmp/detailed_stats.json | jq -r '.performance.avgProcessingTimeSeconds24h // 0')
    THROUGHPUT_PER_HOUR=$(cat /tmp/detailed_stats.json | jq -r '.performance.throughputPerHour // 0')
    EVENTS_LAST_HOUR=$(cat /tmp/detailed_stats.json | jq -r '.performance.eventsProcessedLast1h // 0')
    
    print_info "Avg processing time (24h): ${AVG_PROCESSING_TIME}s"
    print_info "Throughput per hour: ${THROUGHPUT_PER_HOUR}"
    print_info "Events processed last hour: ${EVENTS_LAST_HOUR}"
    
    print_success "Detailed statistics available"
else
    print_error "Failed to get detailed statistics"
    exit 1
fi

# 10. Test mass change aggregation
print_info "10. Testing mass change aggregation..."
MASS_TEST_USER=$(uuidgen)

# VytvoÅ™Ã­me 10 rychlÃ½ch zmÄ›n pro stejnÃ©ho uÅ¾ivatele
for i in {1..10}; do
    docker exec core-db psql -U core -d core -c "
    INSERT INTO user_change_events (user_id, operation, realm_id, payload, processed)
    VALUES (
        '${MASS_TEST_USER}',
        'UPDATE',
        'core-platform',
        '{\"username\": \"mass-test-$i\", \"email\": \"mass$i@test.com\"}',
        false
    );
    "
done

# PoÅ¡leme pouze jednu notifikaci (agregace by mÄ›la vÅ¡echny zpracovat)
docker exec core-db psql -U core -d core -c "NOTIFY user_entity_changed, '${MASS_TEST_USER}';"

# SpustÃ­me flush
curl -sf -X POST "${ADMIN_URL}/api/admin/change-events/flush" > /dev/null

sleep 3

# Zkontrolujeme Å¾e vÅ¡ech 10 eventÅ¯ bylo zpracovÃ¡no jako batch
PROCESSED_MASS_EVENTS=$(docker exec core-db psql -U core -d core -c "
SELECT COUNT(*) FROM user_change_events 
WHERE user_id = '${MASS_TEST_USER}' AND processed = true;
" -t -A)

if [ "$PROCESSED_MASS_EVENTS" -eq 10 ]; then
    print_success "Mass change aggregation working - 10 events processed as batch"
else
    print_warning "Mass aggregation may not be complete - processed: $PROCESSED_MASS_EVENTS/10"
fi

# 11. Final comprehensive health check
print_info "11. Final comprehensive health check..."
if curl -sf "${ADMIN_URL}/api/admin/change-events/health" > /tmp/final_health.json; then
    FINAL_STATUS=$(cat /tmp/final_health.json | jq -r '.status')
    FINAL_LISTENING=$(cat /tmp/final_health.json | jq -r '.processor.listening')
    FINAL_CONNECTION=$(cat /tmp/final_health.json | jq -r '.processor.connectionValid')
    FINAL_UNPROCESSED=$(cat /tmp/final_health.json | jq -r '.database.unprocessedEvents')
    
    print_info "Final status: $FINAL_STATUS"
    print_info "Final listening: $FINAL_LISTENING"
    print_info "Final connection: $FINAL_CONNECTION"
    print_info "Final unprocessed: $FINAL_UNPROCESSED"
    
    if [ "$FINAL_STATUS" = "UP" ]; then
        print_success "Final health check passed"
    else
        print_warning "Final status: $FINAL_STATUS (may be DEGRADED due to test load)"
    fi
fi

# 12. Display optimization summary
print_info "12. V4 Optimization Summary:"
curl -sf "${ADMIN_URL}/api/admin/change-events/config" | jq -r '.optimizations[]' | while read opt; do
    print_info "  âœ“ $opt"
done

# 13. Test safe trigger installation sequencing
print_info "13. Testing safe trigger installation sequencing..."

# Zkontrolujeme Å¾e trigger installation funkce existuje
TRIGGER_FUNC_EXISTS=$(docker exec core-db psql -U core -d core -c "
SELECT EXISTS(SELECT 1 FROM pg_proc WHERE proname = 'ensure_user_sync_triggers_installed') as func_exists;
" -t -A)

if echo "$TRIGGER_FUNC_EXISTS" | grep -q "t"; then
    print_success "Trigger installation function exists"
    
    # Test manuÃ¡lnÃ­ instalace triggerÅ¯
    if curl -sf -X POST "${ADMIN_URL}/api/admin/change-events/install-triggers" > /tmp/install_triggers.json; then
        INSTALL_SUCCESS=$(cat /tmp/install_triggers.json | jq -r '.success')
        KEYCLOAK_DETECTED=$(cat /tmp.install_triggers.json | jq -r '.keycloak_tables_detected')
        TRIGGERS_INSTALLED=$(cat /tmp/install_triggers.json | jq -r '.triggers_installed')
        
        print_info "Installation success: ${INSTALL_SUCCESS}"
        print_info "Keycloak tables detected: ${KEYCLOAK_DETECTED}"
        print_info "Triggers installed: ${TRIGGERS_INSTALLED}"
        
        if [ "$INSTALL_SUCCESS" = "true" ]; then
            print_success "Safe trigger installation working"
            
            if [ "$KEYCLOAK_DETECTED" = "true" ] && [ "$TRIGGERS_INSTALLED" -gt 0 ]; then
                print_success "Keycloak tables detected and triggers installed"
            elif [ "$KEYCLOAK_DETECTED" = "false" ]; then
                print_info "Keycloak tables not ready yet (normal for fresh install)"
            fi
        else
            print_warning "Trigger installation reported issues"
        fi
    else
        print_error "Failed to trigger manual installation"
        exit 1
    fi
else
    print_error "Trigger installation function missing"
    exit 1
fi

echo -e "${GREEN}"
echo "ðŸŽ‰ =============================================="
echo "   V4 Enhanced Tests Completed Successfully!"
echo "   System Features Verified:"
echo "   âœ“ NOOP update detection"
echo "   âœ“ Batch delete processed events" 
echo "   âœ“ Reconnect logic"
echo "   âœ“ Buffer overflow protection"
echo "   âœ“ Mass change aggregation"
echo "   âœ“ Enhanced monitoring"
echo "   âœ“ Database statistics views"
echo "==============================================="
echo -e "${NC}"

# Cleanup temp files
rm -f /tmp/health.json /tmp/config.json /tmp/db_stats.json /tmp/cleanup.json 
rm -f /tmp/reconnect.json /tmp/reconnect_health.json /tmp/buffer_health.json
rm -f /tmp/detailed_stats.json /tmp/final_health.json

print_success "Enhanced PostgreSQL Trigger Sync V4 system is fully operational!"
print_info "Ready for production deployment with all optimizations active."