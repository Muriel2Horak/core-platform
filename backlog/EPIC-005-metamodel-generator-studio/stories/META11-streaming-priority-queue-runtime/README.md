# META-011: Streaming & Priority Queue Runtime âš¡

**EPIC:** [EPIC-005: Metamodel Generator & Studio](../README.md)  
**Status:** ğŸ”´ **CRITICAL** - Schema existuje, runtime CHYBÃ!  
**Priorita:** P0 (Critical - Start Immediately)  
**Estimated LOC:** ~2,000 Å™Ã¡dkÅ¯  
**Effort:** 4 tÃ½dny (160 hodin)

---

## ğŸ“‹ Story Description

Jako **platform developer**, chci **runtime implementaci streaming & priority queue systÃ©mu**, abych **mohl publikovat entity changes do Kafky s prioritizacÃ­ a zajistil event-driven architekturu**.

---

## ğŸ¯ Business Value

**ProÄ je to KRITICKÃ‰:**
- **Schema EXISTUJE** (`StreamingEntityConfig`, `PriorityWeights`) ale **Å½ÃDNÃ RUNTIME**!
- **PÅ¯vodnÃ­ vize**: Fronta pro DB zÃ¡pisy s prioritizacÃ­ (CRITICAL â†’ HIGH â†’ NORMAL â†’ BULK)
- **Blokuje**: CDC, real-time updates, workflow events, reporting streams
- **Impact**: Bez toho nenÃ­ event-driven architecture

**HIGH-LEVEL poÅ¾adavek:**
> 6ï¸âƒ£ Streaming & Eventy: Metamodel urÄuje kterÃ© entity jsou event-sourcovanÃ© / streamovanÃ©, jakÃ½ payload se posÃ­lÃ¡ do Kafky (minimÃ¡lnÄ›: tenantId, entityType, entityId, changeType, version, timestamp, user), sekvence / versioning (optimistic locking, ordering), napojenÃ­ na presence (online lock / kdo edituje), refresh FE po zmÄ›nÄ›, pre-agg/reporting (CDC/streams).

---

## ğŸ¯ Acceptance Criteria

### AC1: Kafka Producer z Entity Changes
- **GIVEN** entita s `streaming.enabled: true`:
  ```yaml
  entity: Order
  streaming:
    enabled: true
    topicPrefix: "core.orders"
    eventPayloadMode: "diff"
  ```
- **WHEN** provedu `POST /api/orders` (create)
- **THEN** Kafka event se publikuje:
  ```json
  {
    "eventType": "OrderCreated",
    "tenantId": 123,
    "entityType": "Order",
    "entityId": "456",
    "changeType": "CREATE",
    "version": 1,
    "timestamp": "2025-11-08T10:30:00Z",
    "user": "user@example.com",
    "payload": {
      "orderId": 456,
      "status": "pending",
      "totalAmount": 299.99
    }
  }
  ```
- **Topic**: `core.orders.order.created`

### AC2: Priority Queue Executor
- **GIVEN** priority weights config:
  ```yaml
  streaming:
    priorityWeights:
      CRITICAL: 1000   # Process first
      HIGH: 100
      NORMAL: 10
      BULK: 1          # Process last
  ```
- **WHEN** v queue jsou:
  - 5 BULK events (e.g., batch import)
  - 1 CRITICAL event (e.g., payment failure)
  - 3 NORMAL events
- **THEN** executor zpracuje v poÅ™adÃ­:
  1. CRITICAL event (okamÅ¾itÄ›)
  2. 3 NORMAL events
  3. 5 BULK events (throttled)

### AC3: CDC Event Format (Change Data Capture)
- **GIVEN** entity update:
  ```sql
  UPDATE products SET price = 150.00 WHERE id = 42;
  ```
- **AND** `eventPayloadMode: "diff"`
- **THEN** Kafka event obsahuje:
  ```json
  {
    "eventType": "ProductUpdated",
    "changeType": "UPDATE",
    "entityId": "42",
    "version": 5,
    "changes": {
      "price": {
        "old": 120.00,
        "new": 150.00
      }
    },
    "fullSnapshot": null  // Only diff, not full entity
  }
  ```

### AC4: Event Payload Modes
- **GIVEN** `eventPayloadMode` konfigurace
- **THEN** podporuje:
  - `minimal`: Pouze `entityId`, `changeType`, `version`
  - `diff`: Minimal + changed fields (old/new values)
  - `full`: Diff + complete entity snapshot

### AC5: DLQ (Dead Letter Queue) Handling
- **GIVEN** Kafka send selhÃ¡nÃ­ (network error)
- **WHEN** retry po 3 pokusech selÅ¾e
- **THEN**:
  - Event se pÅ™esune do `dlq.events` topic
  - Log ERROR: "Event delivery failed after 3 retries"
  - Admin notifikace (email/Slack)

### AC6: Optimistic Locking & Versioning
- **GIVEN** entity s `version` field
- **WHEN** 2 uÅ¾ivatelÃ© editujÃ­ najednou:
  - User A: GET entity (version=5) â†’ UPDATE
  - User B: GET entity (version=5) â†’ UPDATE
- **THEN**:
  - User A: UPDATE succeeds (version=6), event published
  - User B: UPDATE fails `409 Conflict` (stale version)
  - Error message: "Entity was modified by another user"

### AC7: Presence Tracking (Online Lock)
- **GIVEN** entity s `presence.enabled: true`
- **WHEN** User A otevÅ™e detail Order #456
- **THEN**:
  - Websocket message: `{ type: "lock", entityId: 456, user: "userA" }`
  - User B vidÃ­ banner: "User A is editing this order"
  - Po 5 min inactivity â†’ auto-unlock

### AC8: Tenant Scoping v Events
- **GIVEN** multi-tenant entita
- **WHEN** publikuji event
- **THEN** VÅ ECHNY events obsahujÃ­:
  ```json
  {
    "tenantId": 123,  // POVINNÃ‰!
    "entityType": "Order",
    "entityId": "456"
  }
  ```
- **AND** Kafka consumers mohou filtrovat per-tenant

---

## ğŸ—ï¸ Implementation Design

### Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ API Layer (POST /api/orders)                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ EntityEventPublisher (JPA Listener)                     â”‚
â”‚  @PostPersist, @PostUpdate, @PostRemove                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PriorityEventQueue                                      â”‚
â”‚  - calculatePriority(event, config)                     â”‚
â”‚  - enqueue(event, priority)                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â–¼            â–¼            â–¼            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚CRITICAL â”‚ â”‚  HIGH    â”‚ â”‚ NORMAL  â”‚ â”‚  BULK    â”‚
â”‚ Queue   â”‚ â”‚  Queue   â”‚ â”‚  Queue  â”‚ â”‚  Queue   â”‚
â”‚(instant)â”‚ â”‚(100ms)   â”‚ â”‚(1s)     â”‚ â”‚(10s)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚            â”‚            â”‚            â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ KafkaEventProducer                                      â”‚
â”‚  - send(topic, event)                                   â”‚
â”‚  - retry(3 attempts)                                    â”‚
â”‚  - DLQ fallback                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Kafka Topics                                            â”‚
â”‚  - core.orders.order.created                            â”‚
â”‚  - core.orders.order.updated                            â”‚
â”‚  - dlq.events                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Core Components

**1. EntityEventPublisher (JPA Listener)**
```java
@Component
public class EntityEventPublisher {
    
    private final PriorityEventQueue eventQueue;
    private final MetamodelLoader metamodelLoader;
    
    @PostPersist
    public void onEntityCreated(Object entity) {
        EntitySchema schema = metamodelLoader.getSchemaForEntity(entity.getClass());
        
        if (schema.getStreaming() == null || !schema.getStreaming().isEnabled()) {
            return; // Streaming disabled
        }
        
        EntityEvent event = EntityEvent.builder()
            .eventType(schema.getEntity() + "Created")
            .tenantId(extractTenantId(entity))
            .entityType(schema.getEntity())
            .entityId(extractId(entity))
            .changeType(ChangeType.CREATE)
            .version(extractVersion(entity))
            .timestamp(Instant.now())
            .user(SecurityContextHolder.getContext().getAuthentication().getName())
            .payload(buildPayload(entity, schema, null))
            .build();
        
        // Enqueue with priority
        String priority = determinePriority(event, schema);
        eventQueue.enqueue(event, priority);
    }
    
    @PostUpdate
    public void onEntityUpdated(Object entity) {
        // Similar to onEntityCreated, but changeType = UPDATE
        // + detect changed fields for "diff" mode
    }
    
    @PostRemove
    public void onEntityDeleted(Object entity) {
        // changeType = DELETE
        // payload = minimal (just ID)
    }
    
    private String determinePriority(EntityEvent event, EntitySchema schema) {
        // Check if entity has explicit priority field (e.g., order.urgency)
        if (schema.getStreaming().getPriorityField() != null) {
            Object priorityValue = getFieldValue(event.getPayload(), schema.getStreaming().getPriorityField());
            return String.valueOf(priorityValue); // e.g., "CRITICAL"
        }
        
        // Default to workflow transition priority
        return "NORMAL";
    }
}
```

**2. PriorityEventQueue**
```java
@Component
public class PriorityEventQueue {
    
    private final Map<String, BlockingQueue<EntityEvent>> queues = new ConcurrentHashMap<>();
    private final StreamingGlobalConfig config;
    
    @PostConstruct
    public void initQueues() {
        queues.put("CRITICAL", new LinkedBlockingQueue<>());
        queues.put("HIGH", new LinkedBlockingQueue<>());
        queues.put("NORMAL", new LinkedBlockingQueue<>());
        queues.put("BULK", new LinkedBlockingQueue<>());
        
        // Start consumer threads for each priority
        startConsumer("CRITICAL", config.getPriorityWeights().getCritical());
        startConsumer("HIGH", config.getPriorityWeights().getHigh());
        startConsumer("NORMAL", config.getPriorityWeights().getNormal());
        startConsumer("BULK", config.getPriorityWeights().getBulk());
    }
    
    public void enqueue(EntityEvent event, String priority) {
        BlockingQueue<EntityEvent> queue = queues.get(priority);
        if (queue == null) {
            queue = queues.get("NORMAL"); // Fallback
        }
        queue.offer(event);
        log.debug("Enqueued {} event with priority {}", event.getEventType(), priority);
    }
    
    private void startConsumer(String priority, int weight) {
        // Weight determines delay between processing
        long delayMs = calculateDelay(weight);
        
        Thread consumer = new Thread(() -> {
            while (true) {
                try {
                    EntityEvent event = queues.get(priority).take();
                    kafkaEventProducer.send(event);
                    
                    // Throttle based on weight
                    Thread.sleep(delayMs);
                } catch (InterruptedException e) {
                    Thread.currentThread().interrupt();
                    break;
                }
            }
        });
        consumer.setName("EventConsumer-" + priority);
        consumer.start();
    }
    
    private long calculateDelay(int weight) {
        // Higher weight = lower delay
        // CRITICAL (1000) â†’ 0ms
        // HIGH (100) â†’ 10ms
        // NORMAL (10) â†’ 100ms
        // BULK (1) â†’ 1000ms
        return Math.max(0, 1000 - weight);
    }
}
```

**3. KafkaEventProducer**
```java
@Service
public class KafkaEventProducer {
    
    private final KafkaTemplate<String, EntityEvent> kafkaTemplate;
    private final StreamingGlobalConfig config;
    
    public void send(EntityEvent event) {
        String topic = buildTopicName(event);
        
        try {
            kafkaTemplate.send(topic, event.getEntityId(), event)
                .thenAccept(result -> {
                    log.info("Event published: {} to {}", event.getEventType(), topic);
                })
                .exceptionally(ex -> {
                    handleSendFailure(event, topic, ex);
                    return null;
                });
        } catch (Exception e) {
            handleSendFailure(event, topic, e);
        }
    }
    
    private String buildTopicName(EntityEvent event) {
        // core.orders.order.created
        return String.format("%s.%s.%s",
            config.getTopicPrefix(),
            event.getEntityType().toLowerCase(),
            event.getChangeType().toString().toLowerCase()
        );
    }
    
    private void handleSendFailure(EntityEvent event, String topic, Throwable error) {
        log.error("Failed to send event {} to {}: {}", event.getEventType(), topic, error.getMessage());
        
        // Retry 3x with exponential backoff
        for (int attempt = 1; attempt <= 3; attempt++) {
            try {
                Thread.sleep(attempt * 1000); // 1s, 2s, 3s
                kafkaTemplate.send(topic, event.getEntityId(), event).get();
                log.info("Event sent successfully on retry {}", attempt);
                return;
            } catch (Exception retryEx) {
                log.warn("Retry {} failed: {}", attempt, retryEx.getMessage());
            }
        }
        
        // All retries failed â†’ DLQ
        sendToDLQ(event, error);
    }
    
    private void sendToDLQ(EntityEvent event, Throwable error) {
        String dlqTopic = config.getDlqTopic();
        
        DLQEvent dlqEvent = DLQEvent.builder()
            .originalEvent(event)
            .failureReason(error.getMessage())
            .failureTimestamp(Instant.now())
            .retryCount(3)
            .build();
        
        kafkaTemplate.send(dlqTopic, event.getEntityId(), dlqEvent);
        
        log.error("Event moved to DLQ: {}", event.getEventType());
        
        // Send admin notification
        notificationService.sendAlert(
            "Kafka Event Delivery Failed",
            String.format("Event %s failed after 3 retries. Check DLQ topic: %s", 
                event.getEventType(), dlqTopic)
        );
    }
}
```

**4. Payload Builder (diff/full/minimal modes)**
```java
@Component
public class EventPayloadBuilder {
    
    public Object buildPayload(Object entity, EntitySchema schema, Object oldEntity) {
        String mode = schema.getStreaming().getEventPayloadMode();
        
        switch (mode) {
            case "minimal":
                return Map.of(
                    "entityId", extractId(entity),
                    "version", extractVersion(entity)
                );
            
            case "diff":
                if (oldEntity == null) {
                    // CREATE â†’ full entity
                    return serializeEntity(entity, schema);
                } else {
                    // UPDATE â†’ only changed fields
                    return detectChanges(oldEntity, entity, schema);
                }
            
            case "full":
                return Map.of(
                    "snapshot", serializeEntity(entity, schema),
                    "changes", oldEntity != null ? detectChanges(oldEntity, entity, schema) : null
                );
            
            default:
                throw new IllegalArgumentException("Unknown payload mode: " + mode);
        }
    }
    
    private Map<String, FieldChange> detectChanges(Object oldEntity, Object newEntity, EntitySchema schema) {
        Map<String, FieldChange> changes = new HashMap<>();
        
        for (FieldSchema field : schema.getFields()) {
            Object oldValue = getFieldValue(oldEntity, field.getName());
            Object newValue = getFieldValue(newEntity, field.getName());
            
            if (!Objects.equals(oldValue, newValue)) {
                changes.put(field.getName(), new FieldChange(oldValue, newValue));
            }
        }
        
        return changes;
    }
}
```

**5. Optimistic Locking Support**
```java
@Entity
@Table(name = "products")
public class Product {
    
    @Id
    private Long id;
    
    @Version  // JPA optimistic locking
    private Long version;
    
    private String name;
    private BigDecimal price;
    
    // When 2 users update:
    // User A: version=5 â†’ UPDATE succeeds (version=6)
    // User B: version=5 â†’ OptimisticLockException (stale)
}

@ControllerAdvice
public class OptimisticLockExceptionHandler {
    
    @ExceptionHandler(OptimisticLockException.class)
    public ResponseEntity<?> handleStaleLock(OptimisticLockException ex) {
        return ResponseEntity.status(HttpStatus.CONFLICT)
            .body(Map.of(
                "error", "EntityModifiedByAnotherUser",
                "message", "Entity was modified by another user. Please refresh and try again."
            ));
    }
}
```

**6. Presence Tracking (WebSocket)**
```java
@Component
public class PresenceTracker {
    
    private final SimpMessagingTemplate messagingTemplate;
    private final Map<String, Set<String>> entityLocks = new ConcurrentHashMap<>();
    
    @MessageMapping("/presence/lock")
    public void lockEntity(@Payload LockRequest request, Principal user) {
        String entityKey = request.getEntityType() + ":" + request.getEntityId();
        
        entityLocks.computeIfAbsent(entityKey, k -> ConcurrentHashMap.newKeySet())
            .add(user.getName());
        
        // Broadcast to all users viewing this entity
        messagingTemplate.convertAndSend(
            "/topic/presence/" + entityKey,
            Map.of(
                "type", "locked",
                "user", user.getName(),
                "timestamp", Instant.now()
            )
        );
        
        // Auto-unlock after 5 minutes
        scheduleAutoUnlock(entityKey, user.getName(), Duration.ofMinutes(5));
    }
}
```

---

## ğŸ§ª Testing Strategy

### Unit Tests
```java
@Test
void shouldEnqueueEventWithCorrectPriority() {
    EntityEvent criticalEvent = createEvent("PaymentFailed", "CRITICAL");
    EntityEvent normalEvent = createEvent("OrderCreated", "NORMAL");
    
    queue.enqueue(criticalEvent, "CRITICAL");
    queue.enqueue(normalEvent, "NORMAL");
    
    // CRITICAL should be processed first
    verify(kafkaProducer).send(argThat(e -> e.getEventType().equals("PaymentFailed")));
}

@Test
void shouldMoveToDLQAfter3Retries() {
    when(kafkaTemplate.send(anyString(), anyString(), any()))
        .thenThrow(new RuntimeException("Network error"));
    
    kafkaProducer.send(createEvent("OrderCreated", "NORMAL"));
    
    verify(kafkaTemplate, times(4)).send(anyString(), anyString(), any()); // 1 + 3 retries
    verify(kafkaTemplate).send(eq("dlq.events"), anyString(), any(DLQEvent.class));
}
```

---

## ğŸ“¦ Deliverables

1. **Event Publishing** (~600 LOC)
   - `EntityEventPublisher.java`
   - `EventPayloadBuilder.java`

2. **Priority Queue** (~500 LOC)
   - `PriorityEventQueue.java`
   - `EventConsumerThread.java`

3. **Kafka Integration** (~400 LOC)
   - `KafkaEventProducer.java`
   - `DLQHandler.java`

4. **Presence & Locking** (~300 LOC)
   - `PresenceTracker.java`
   - `OptimisticLockHandler.java`

5. **Tests** (~500 LOC)

---

## ğŸ¯ Success Metrics

- âœ… Events publikovÃ¡ny do Kafky pro vÅ¡echny entity changes
- âœ… Priority queue funguje (CRITICAL â†’ BULK poÅ™adÃ­)
- âœ… DLQ zachytÃ­ < 0.1% failed events
- âœ… Optimistic locking zabrÃ¡nÃ­ concurrent updates

---

**Story Owner:** Backend Team  
**Priority:** P0 - CRITICAL  
**Effort:** 4 tÃ½dny  
**Start ASAP:** Schema existuje, runtime MUSÃ bÃ½t hotovÃ½!
